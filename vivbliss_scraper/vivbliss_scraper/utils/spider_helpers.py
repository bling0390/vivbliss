#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çˆ¬è™«è¾…åŠ©å·¥å…·
æä¾›çˆ¬è™«å¼€å‘ä¸­å¸¸ç”¨çš„å·¥å…·å‡½æ•°å’Œè£…é¥°å™¨
"""

import time
import functools
from typing import Callable, Any, Dict, List, Optional
from datetime import datetime
import logging


def timing_decorator(func: Callable) -> Callable:
    """
    è®¡æ—¶è£…é¥°å™¨ï¼Œç”¨äºæµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´
    
    Args:
        func: è¦è£…é¥°çš„å‡½æ•°
        
    Returns:
        è£…é¥°åçš„å‡½æ•°
    """
    @functools.wraps(func)
    def wrapper(self, *args, **kwargs):
        start_time = time.time()
        result = func(self, *args, **kwargs)
        end_time = time.time()
        
        duration = end_time - start_time
        if hasattr(self, 'logger'):
            self.logger.info(f"â±ï¸  {func.__name__} æ‰§è¡Œè€—æ—¶: {duration:.2f} ç§’")
        
        return result
    return wrapper


def error_handler(default_return=None, log_error=True):
    """
    é”™è¯¯å¤„ç†è£…é¥°å™¨
    
    Args:
        default_return: å‡ºé”™æ—¶çš„é»˜è®¤è¿”å›å€¼
        log_error: æ˜¯å¦è®°å½•é”™è¯¯æ—¥å¿—
        
    Returns:
        è£…é¥°å™¨å‡½æ•°
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(self, *args, **kwargs):
            try:
                return func(self, *args, **kwargs)
            except Exception as e:
                if log_error and hasattr(self, 'logger'):
                    self.logger.error(f"âŒ {func.__name__} å‡ºç°é”™è¯¯: {e}")
                return default_return
        return wrapper
    return decorator


class SpiderStats:
    """çˆ¬è™«ç»Ÿè®¡ä¿¡æ¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.start_time = time.time()
        self.stats = {
            'categories_discovered': 0,
            'categories_processed': 0,
            'products_discovered': 0,
            'products_processed': 0,
            'errors': 0,
            'requests_sent': 0,
            'responses_received': 0
        }
        self.detailed_stats = {
            'categories': [],
            'products': [],
            'errors': []
        }
    
    def increment(self, stat_name: str, count: int = 1):
        """å¢åŠ ç»Ÿè®¡è®¡æ•°"""
        if stat_name in self.stats:
            self.stats[stat_name] += count
    
    def add_category_stat(self, category_info: Dict[str, Any]):
        """æ·»åŠ åˆ†ç±»ç»Ÿè®¡ä¿¡æ¯"""
        category_info['processed_at'] = datetime.now().isoformat()
        self.detailed_stats['categories'].append(category_info)
        self.increment('categories_processed')
    
    def add_product_stat(self, product_info: Dict[str, Any]):
        """æ·»åŠ äº§å“ç»Ÿè®¡ä¿¡æ¯"""
        product_info['processed_at'] = datetime.now().isoformat()
        self.detailed_stats['products'].append(product_info)
        self.increment('products_processed')
    
    def add_error_stat(self, error_info: Dict[str, Any]):
        """æ·»åŠ é”™è¯¯ç»Ÿè®¡ä¿¡æ¯"""
        error_info['occurred_at'] = datetime.now().isoformat()
        self.detailed_stats['errors'].append(error_info)
        self.increment('errors')
    
    def get_runtime(self) -> float:
        """è·å–è¿è¡Œæ—¶é—´"""
        return time.time() - self.start_time
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        runtime = self.get_runtime()
        
        summary = {
            'runtime_seconds': runtime,
            'total_categories': self.stats['categories_processed'],
            'total_products': self.stats['products_processed'],
            'total_errors': self.stats['errors'],
            'success_rate': self._calculate_success_rate(),
            'processing_speed': {
                'categories_per_second': self.stats['categories_processed'] / runtime if runtime > 0 else 0,
                'products_per_second': self.stats['products_processed'] / runtime if runtime > 0 else 0
            }
        }
        
        return summary
    
    def _calculate_success_rate(self) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        total_items = self.stats['categories_processed'] + self.stats['products_processed']
        if total_items == 0:
            return 0.0
        
        success_items = total_items - self.stats['errors']
        return (success_items / total_items) * 100


class RequestBuilder:
    """è¯·æ±‚æ„å»ºå·¥å…·"""
    
    @staticmethod
    def build_category_request(url: str, category_info: Dict[str, Any], callback: Callable):
        """æ„å»ºåˆ†ç±»è¯·æ±‚"""
        try:
            import scrapy
            return scrapy.Request(
                url=url,
                callback=callback,
                meta={
                    'category_name': category_info.get('text', 'æœªçŸ¥åˆ†ç±»'),
                    'category_url': category_info.get('url'),
                    'level': category_info.get('level', 1),
                    'parent_category': category_info.get('parent_category'),
                    'request_type': 'category'
                }
            )
        except ImportError:
            # å¦‚æœæ²¡æœ‰scrapyï¼Œè¿”å›æ¨¡æ‹Ÿå¯¹è±¡
            class MockRequest:
                def __init__(self, url, callback, meta):
                    self.url = url
                    self.callback = callback
                    self.meta = meta
            
            return MockRequest(url, callback, {
                'category_name': category_info.get('text', 'æœªçŸ¥åˆ†ç±»'),
                'category_url': category_info.get('url'),
                'level': category_info.get('level', 1),
                'parent_category': category_info.get('parent_category'),
                'request_type': 'category'
            })
    
    @staticmethod
    def build_product_request(url: str, product_info: Dict[str, Any], callback: Callable, category_path: str = None):
        """æ„å»ºäº§å“è¯·æ±‚"""
        try:
            import scrapy
            return scrapy.Request(
                url=url,
                callback=callback,
                meta={
                    'product_name': product_info.get('text', 'æœªçŸ¥äº§å“'),
                    'product_url': product_info.get('url'),
                    'category_path': category_path or 'æœªåˆ†ç±»',
                    'request_type': 'product'
                }
            )
        except ImportError:
            # å¦‚æœæ²¡æœ‰scrapyï¼Œè¿”å›æ¨¡æ‹Ÿå¯¹è±¡
            class MockRequest:
                def __init__(self, url, callback, meta):
                    self.url = url
                    self.callback = callback
                    self.meta = meta
            
            return MockRequest(url, callback, {
                'product_name': product_info.get('text', 'æœªçŸ¥äº§å“'),
                'product_url': product_info.get('url'),
                'category_path': category_path or 'æœªåˆ†ç±»',
                'request_type': 'product'
            })


class ResponseAnalyzer:
    """å“åº”åˆ†æå·¥å…·"""
    
    @staticmethod
    def analyze_page_structure(response) -> Dict[str, Any]:
        """
        åˆ†æé¡µé¢ç»“æ„
        
        Args:
            response: Scrapyå“åº”å¯¹è±¡
            
        Returns:
            é¡µé¢ç»“æ„åˆ†æç»“æœ
        """
        try:
            analysis = {
                'url': response.url,
                'status_code': response.status,
                'content_length': len(response.body),
                'content_type': response.headers.get('Content-Type', b'unknown').decode(),
                'page_structure': {
                    'title_count': len(response.css('title')),
                    'h1_count': len(response.css('h1')),
                    'h2_count': len(response.css('h2')),
                    'div_count': len(response.css('div')),
                    'link_count': len(response.css('a')),
                    'image_count': len(response.css('img')),
                    'form_count': len(response.css('form')),
                },
                'potential_categories': ResponseAnalyzer._count_potential_categories(response),
                'potential_products': ResponseAnalyzer._count_potential_products(response)
            }
            
            return analysis
        except Exception as e:
            return {
                'error': str(e),
                'url': getattr(response, 'url', 'unknown'),
                'analysis_failed': True
            }
    
    @staticmethod
    def _count_potential_categories(response) -> int:
        """è®¡ç®—æ½œåœ¨åˆ†ç±»æ•°é‡"""
        category_selectors = [
            'a[href*="category"]',
            'a[href*="categories"]',
            '.category-link',
            '.nav-menu a'
        ]
        
        total_count = 0
        for selector in category_selectors:
            try:
                count = len(response.css(selector))
                total_count += count
            except Exception:
                continue
        
        return total_count
    
    @staticmethod
    def _count_potential_products(response) -> int:
        """è®¡ç®—æ½œåœ¨äº§å“æ•°é‡"""
        product_selectors = [
            'a[href*="product"]',
            '.product-item',
            '.product-card',
            '.shop-item'
        ]
        
        total_count = 0
        for selector in product_selectors:
            try:
                count = len(response.css(selector))
                total_count += count
            except Exception:
                continue
        
        return total_count


class LoggingHelper:
    """æ—¥å¿—è¾…åŠ©å·¥å…·"""
    
    @staticmethod
    def log_spider_start(logger, spider_name: str, config: Dict[str, Any]):
        """è®°å½•çˆ¬è™«å¯åŠ¨æ—¥å¿—"""
        logger.info(f'\nğŸš€ å¼€å§‹çˆ¬å– {spider_name} çˆ¬è™«')
        logger.info(f'ğŸ¯ ç›®æ ‡åŸŸå: {config.get("allowed_domains", [])}')
        logger.info(f'ğŸ“‹ èµ·å§‹URLæ•°é‡: {len(config.get("start_urls", []))}')
        logger.info(f'âš™ï¸  çˆ¬è™«é…ç½®:')
        for key, value in config.items():
            if key not in ['allowed_domains', 'start_urls']:
                logger.info(f'   {key}: {value}')
    
    @staticmethod
    def log_spider_end(logger, spider_name: str, stats: SpiderStats):
        """è®°å½•çˆ¬è™«ç»“æŸæ—¥å¿—"""
        summary = stats.get_summary()
        
        logger.info(f'\nğŸ çˆ¬è™« {spider_name} ç»“æŸè¿è¡Œ')
        logger.info(f'ğŸ“Š çˆ¬å–ç»Ÿè®¡:')
        logger.info(f'   æ€»å¤„ç†åˆ†ç±»: {summary["total_categories"]} ä¸ª')
        logger.info(f'   æ€»å¤„ç†äº§å“: {summary["total_products"]} ä¸ª')
        logger.info(f'   æ€»è€—æ—¶: {summary["runtime_seconds"]:.2f} ç§’')
        logger.info(f'   æˆåŠŸç‡: {summary["success_rate"]:.1f}%')
        logger.info(f'   å¤„ç†é€Ÿåº¦: {summary["processing_speed"]["products_per_second"]:.2f} äº§å“/ç§’')
    
    @staticmethod
    def log_page_processing(logger, response, processing_type: str = "é¡µé¢"):
        """è®°å½•é¡µé¢å¤„ç†æ—¥å¿—"""
        logger.info(f'\n=== å¼€å§‹è§£æ{processing_type} ===')
        logger.info(f'URL: {response.url}')
        logger.info(f'çŠ¶æ€ç : {response.status}')
        logger.info(f'å“åº”å¤§å°: {len(response.body)} bytes')
        
        try:
            content_type = response.headers.get('Content-Type', b'unknown').decode()
            logger.info(f'Content-Type: {content_type}')
        except Exception:
            logger.info(f'Content-Type: unknown')
    
    @staticmethod
    def log_item_extraction(logger, item_type: str, item_data: Dict[str, Any], index: int = None):
        """è®°å½•æ•°æ®é¡¹æå–æ—¥å¿—"""
        prefix = f"#{index}" if index is not None else ""
        logger.info(f'âœ… æå–{item_type} {prefix}:')
        
        # åªè®°å½•å…³é”®å­—æ®µï¼Œé¿å…æ—¥å¿—è¿‡é•¿
        key_fields = {
            'åˆ†ç±»': ['name', 'url', 'level', 'product_count'],
            'äº§å“': ['name', 'url', 'price', 'stock_status', 'rating']
        }
        
        fields_to_log = key_fields.get(item_type, list(item_data.keys())[:5])
        
        for field in fields_to_log:
            if field in item_data and item_data[field] is not None:
                value = item_data[field]
                if isinstance(value, str) and len(value) > 50:
                    value = value[:47] + '...'
                logger.info(f'   {field}: {value}')
    
    @staticmethod
    def log_discovery_results(logger, discovery_type: str, discovered_items: List[Dict[str, Any]]):
        """è®°å½•å‘ç°ç»“æœæ—¥å¿—"""
        logger.info(f'ğŸ” {discovery_type}å‘ç°ç»“æœ:')
        logger.info(f'   æ€»è®¡å‘ç°: {len(discovered_items)} ä¸ª{discovery_type}')
        
        # è®°å½•å‰å‡ ä¸ªå‘ç°çš„é¡¹ç›®
        for i, item in enumerate(discovered_items[:5], 1):
            text = item.get('text', 'æœªçŸ¥')
            url = item.get('url', 'æœªçŸ¥')
            logger.info(f'   {i}. {text} -> {url}')
        
        if len(discovered_items) > 5:
            logger.info(f'   ... è¿˜æœ‰ {len(discovered_items) - 5} ä¸ª{discovery_type}')


class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    
    def __init__(self, max_requests_per_second: int = 1):
        self.max_requests_per_second = max_requests_per_second
        self.last_request_time = 0
        self.request_interval = 1.0 / max_requests_per_second
    
    def wait_if_needed(self):
        """å¦‚æœéœ€è¦ï¼Œç­‰å¾…ä»¥é™åˆ¶è¯·æ±‚é€Ÿç‡"""
        current_time = time.time()
        time_since_last_request = current_time - self.last_request_time
        
        if time_since_last_request < self.request_interval:
            wait_time = self.request_interval - time_since_last_request
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    def can_make_request(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å‘å‡ºè¯·æ±‚"""
        current_time = time.time()
        return (current_time - self.last_request_time) >= self.request_interval


class UrlPatternMatcher:
    """URLæ¨¡å¼åŒ¹é…å™¨"""
    
    # é¢„å®šä¹‰çš„URLæ¨¡å¼
    CATEGORY_PATTERNS = [
        r'/category/[\w\-/]+',
        r'/categories/[\w\-/]+',
        r'/cat/[\w\-/]+',
        r'/shop/[\w\-/]+',
        r'/collection/[\w\-/]+'
    ]
    
    PRODUCT_PATTERNS = [
        r'/product/[\w\-/]+',
        r'/products/[\w\-/]+',
        r'/item/[\w\-/]+',
        r'/shop/.+/product/.+'
    ]
    
    @classmethod
    def is_category_url(cls, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯åˆ†ç±»URL"""
        if not url:
            return False
        
        import re
        return any(re.search(pattern, url) for pattern in cls.CATEGORY_PATTERNS)
    
    @classmethod
    def is_product_url(cls, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯äº§å“URL"""
        if not url:
            return False
        
        import re
        return any(re.search(pattern, url) for pattern in cls.PRODUCT_PATTERNS)
    
    @classmethod
    def extract_category_slug(cls, url: str) -> Optional[str]:
        """ä»åˆ†ç±»URLä¸­æå–slug"""
        if not cls.is_category_url(url):
            return None
        
        # æå–æœ€åä¸€ä¸ªè·¯å¾„æ®µä½œä¸ºslug
        parts = url.strip('/').split('/')
        return parts[-1] if parts else None
    
    @classmethod
    def extract_product_slug(cls, url: str) -> Optional[str]:
        """ä»äº§å“URLä¸­æå–slug"""
        if not cls.is_product_url(url):
            return None
        
        # æå–æœ€åä¸€ä¸ªè·¯å¾„æ®µä½œä¸ºslug
        parts = url.strip('/').split('/')
        return parts[-1] if parts else None